<html>
  <head>
    <title>Sam Heslop</title>
    <meta charset="utf-8">
    <link rel="shortcut icon" type="image/jpeg" href="./favicon.ico"/>
    <link rel="stylesheet" type="text/css" href="../style.css">
    <link href="https://fonts.googleapis.com/css?family=Oxygen" rel="stylesheet">
  </head>
  <body>
    <div>
      <p><a href="https://samheslop.com" class="me">Sam Heslop</a><p>
    </div>
    <div id="md">
      <h1 id="deterministicbucketingbyemailaddress">Deterministic Bucketing by Email Address</h1>
<p>Imagine you wanted to split your user base into two groups, with the A set being sent to a beta version of your site, and the B's continuing to view the regular version. The criteria for entering either bucket should be entirely random, and the percentages assigned to each bucket should be variable (you'll want to increment this percentage over time as confidence in the beta version increases). We had a similar requirement for a new feature at Ravelin, and so I wanted to take a look into how I could write something to achieve this desired effect, without using any persistence, and instead relying on the wonders of crypto.  </p>
<p>For the purpose of this post, let's set out some requirements for our implementation. We expect the same customer to always be placed into the same bucket, and we expect the total split of customers in Bucket A vs Bucket B to match our desired percentages. We'll use the customer's email address to calculate this, under the assumption that it is both unique and immutable per account. We'll also not be too fussy about the distribution being perfect, but we'd hope given a sufficiently large data set, we'll be pretty close. If our implementation is pretty performant, that would also be a nice bonus.</p>
<h2 id="propertiesofhashingalgorithms">Properties of Hashing Algorithms</h2>
<p>Hashing algorithms are designed to have uniformly distributed outputs; the more uniform this distribution, the less information a cryptanalysis can glean from any given output. They are also designed to accommodate a range of inputs, both in length and in character sets, something important if we are to accept the entire breadth of valid email addresses. Of course, they are also deterministic in their nature, so we're guaranteed our customers will stay in their allotted bucket across the life of their account. Most importantly though, crypto implementations are amongst the most scrutinised and therefore, the most robust functions you can find, so we can be confident all the aforementioned properties are genuinely present in whichever popular hashing func implementation we chose from the Go stdlib, without the need for us to independently verify them.</p>
<h2 id="atestsuiteforourimplementation">A Test Suite for our Implementation</h2>
<p>While I have little faith in my mathematical abilities, I am confident I can write a robust test suite to test our potential implementation meets the base requirements for our case. This suite is written assuming we will be implementing a func with the given signature <code>assignEmailAddress(s string) (int, error)</code>, where the returned int is a number between 0 and 99 that we can easily compare to our desired percentile to bucket the user.</p>
<pre><code>func TestBucketEmailAddress(t *testing.T) {
    input := []string{
        "this_is.our-first!test+case@test.com",
        "smol@a.c",
        "samuel.heslop.dev@gmail.com",
        "sam.heslop@ravelin.com",

        // Let's also grab loads of cases from the net/mail packages tests
        // https://github.com/golang/go/blob/master/src/net/mail/message_test.go#L792
        `Bob@example.com`,
        `bob.bob@example.com`,
        `".bob"@example.com`,
        `" "@example.com`,
        `some.mail-with-dash@example.com`,
        `"dot.and space"@example.com`,
        `"very.unusual.@.unusual.com"@example.com`,
        `admin@mailserver1`,
        `postmaster@localhost`,
        "#!$%&amp;'*+-/=?^_`{}|~@example.org",
        `"very.(),:;&lt;&gt;[]\".VERY.\"very@\\ \"very\".unusual"@strange.example.com`,
        `"()&lt;&gt;[]:,;@\\\"!#$%&amp;'*+-/=?^_{}| ~.a"@example.org`,
        `"Abc\\@def"@example.com`,
        `"Joe\\Blow"@example.com`,
        `test1/test2=test3@example.com`,
        `def!xyz«c@example.com`,
        `_somename@example.com`,
        `joe@uk`,
        `~@example.com`,
        `"..."@test.com`,
        `"john..doe"@example.com`,
        `"john.doe."@example.com`,
        `".john.doe"@example.com`,
        `"."@example.com`,
        `".."@example.com`,
        `"0:"@0`,
    }

    for _, s := range input {
        // First, let's check out function is truly deterministic
        r1, err1 := bucketEmailAddress(s)
        r2, err2 := bucketEmailAddress(s)

        if err1 != nil {
            t.Fatalf("Unexpected err produced from bucketEmailAddress for input %s. %s", s, err1.Error())
        }
        if err2 != nil {
            t.Fatalf("Unexpected err produced from bucketEmailAddress for input %s. %s", s, err2.Error())
        }

        if r1 != r2 {
            t.Fatalf("Expected bucketEmailAddress to be deterministic. Got %d and %d for input %s", r1, r2, s)
        }

        // Next, let's repeatedly manipulate our input to create a distribution map across different inputs
        letterIncrements := 150
        distribution := make(map[int]int)
        for i := 0; i &lt; len(s); i++ {
            b := []byte(s)
            for ii := 0; ii &lt; letterIncrements; ii++ {
                b[i] = byte(int(b[i]) + ii)
                result, _ := bucketEmailAddress(string(b))
                distribution[result]++
            }
        }

        // Let's do the same in reverse as well to double our sample range
        for i := 0; i &lt; len(s); i++ {
            b := []byte(s)
            for ii := 0; ii &lt; letterIncrements; ii++ {
                b[i] = byte(int(b[i]) - ii)
                result, _ := bucketEmailAddress(string(b))
                distribution[result]++
            }
        }

        // We expect this distribution to cover every value from 0 to 99
        if len(distribution) != 100 {
            t.Fatalf("Expected range of distribution to cover 0 through to 99 for %s", s)
        }

        // Let's also make sure that no one of our point contains more than 2% of the total..
        max := (((len(s) * letterIncrements * 2) / 100) * 2)
        for k, v := range distribution {
            if v &gt; max {
                t.Fatalf("Unlikely that distribution for percentile %d should ever exceed %d, yet got %d for %s", k, max, v, s)
            }
        }

        // ... and no less than 0.5% of the total as the minimum
        min := (((len(s) * letterIncrements * 2) / 100) / 5)
        for k, v := range distribution {
            if v &lt; min {
                t.Fatalf("Unlikely that distribution for percentile %d should ever be lower than %d, yet got %d for %s", k, min, v, s)
            }
        }
    }
}
</code></pre>
<h2 id="implementation">Implementation</h2>
<p>My first instinct was that any old hashing algo and some modulo math should get us pretty close to our desired results.</p>
<pre><code>func bucketEmailAddress(s string) (int, error) {
    h := sha512.New()
    h.Write([]byte(s))

    b := h.Sum(nil)
    var result int
    result += (int(b[8]) % 10) * 10
    result += int(b[31]) % 10

    return result, nil
}
</code></pre>
<p>Nothing too exciting going on here. The modulo math is fairly straight forward, first using a modulo expression * 10 to produce a multiple of 10 with the addition of the result of a second modulo expression to produce a value between 0 and 99. I chose the indexes of 8 and 31 randomly, knowing the block manipulations steps in the SHA512 implementation are designed to give no individual bit greater significance than any other. </p>
<p>This implementation satisfies our test cases, but I wonder how robust it is… what happens for example if we adjust one of our indexes? Let's change that b[8] to b[9]…</p>
<p><code>Unlikely that distribution for percentile 1 should ever exceed 138, yet got 140 for "Joe\\Blow"@example.com</code></p>
<p>As expected, our unscientific approach to distribution is fairly brittle. Perhaps another round of hashing would help make this more reliable…</p>
<p><code>Unlikely that distribution for percentile 24 should ever exceed 126, yet got 133 for _somename@example.com</code></p>
<p>Or perhaps the problem is our SHA512 algo? Let's swap it out for SHA256…</p>
<p><code>Unlikely that distribution for percentile 96 should ever exceed 90, yet got 113 for Bob@example.com</code></p>
<p>After several rounds of fiddling and tinkering with the implementation, there was only one way I found to reliably improve the accuracy of this test, increasing the size of the data set we test against. Specifically, I was manipulating this through the <code>letterIncrements</code> variable; setting it all the way up to 300 proved the implementation robust enough for our test suite.</p>
<h2 id="tldr">tldr;</h2>
<p>As expected, we can rely on the inate properties of hash functions and a little bit of modulo math to bucket arbitrary strings deterministically, just be sure that your sample size is sufficiently large. Cool. This ended up being easier than I expected, but I'm glad I went through it regardless.</p>
    </div>
    <script src="../highlight.pack.js"></script>
    <script>
    window.onload = function(){var aCodes=document.getElementsByTagName('pre');for(var i=0;i<aCodes.length;i++) {hljs.highlightBlock(aCodes[i]);}};
    </script>
  </body>
</html>