<html>
  <head>
    <title>Sam Heslop</title>
    <meta charset="utf-8">
    <link rel="shortcut icon" type="image/jpeg" href="../favicon.ico"/>
    <link rel="stylesheet" type="text/css" href="../style.css">
  </head>
  <body>
    <div>
      <p><a href="https://samheslop.com" class="me">Sam Heslop</a><p>
    </div>
    <div id="md">
      <h1 id="verifyingcontainerisedbinaries">Verifying Containerised Binaries</h1>
<p>With the rise of containerisation, including the distribution of containerised cli tools, like this <a href="https://github.com/bitnami/bitnami-docker-kubectl">bitnami/kubectl</a> image or this <a href="https://hub.docker.com/r/rancher/crictl">crictl image</a> distributed by Rancher that I mentioned in a <a href="https://samheslop.com/posts/20210325_containerd_on_gke.html">previous post</a>, there is a new opportunity attackers can look to exploit; <strong>not many people take the time to vet the images they are choosing to run on their local machine actually contain a binary compiled from open-source code, and not some backdoored/compromised version</strong>.</p>
<p>Here, we're specifically talking about;</p>
<ul>
<li>adversaries who develop and share useful tools with the intent to distribute backdoored versions in their containers</li>
<li>typosquatting/impersonation, where an adversary outside of the core maintainers of a project pushes an unofficial, backdoored image with the hope their image is mistakenly/carelessly pulled instead of an official version</li>
</ul>
<h2 id="unpackinganimage">Unpacking an Image</h2>
<p>In order to perform a checksum on the binary distributed inside of an image, we will first need to 'unpack' that image. I like to think of images as a 2d representation of a container, with the filesystem flattened down into layers like it's been through a VacPack. We can re-inflate this image into a filesystem (just as your container runtime does when it launches the container) and use a checksum command like <code>sha</code>, targeting the binary in this newly unpacked filesystem. </p>
<p>Using a couple trusty open-source projects, we can do something like the following;</p>
<pre><code>skopeo copy docker://rancher/crictl:v1.19.0 oci:crictl:v1.19.0
sudo umoci unpack --image crictl:v1.19.0 crictl-unpacked
sha -a 256 crictl-unpacked/rootfs/$path/$to/$binary/crictl
</code></pre>
<p>There are a few things to note about this process:</p>
<ul>
<li><a href="https://github.com/opencontainers/umoci">umoci</a>, the tool we're using to unpack the image, only works on OCI format images, so when pulling the image locally via <a href="https://github.com/containers/skopeo">skopeo</a>, must specify that <code>oci:$image:$tag</code> </li>
<li>If you need to find where the binary is located in the image, you can <code>docker inspect</code> the image to find the <code>PATH</code> and the entrypoint/cmd inside the <code>config</code> blob. This <code>config</code> blob in the <a href="https://github.com/opencontainers/image-spec/blob/master/config.md#properties">OCI spec</a> is loosely defined, with all fields being optional. This means we can't be guaranteed that either entrypoint or cmd will be present, you'll need to check both. </li>
<li>All of this functionality is also available through a combination of the <code>github.com/opencontainers/umoci</code> and <code>github.com/containers/image</code> libraries. Maybe one day I'll bundle this all up into a standalone cliâ€¦</li>
</ul>
<h2 id="whydontwejustruntheimage">Why don't we just run the image?</h2>
<p>Alternatively, you could just run the image and perform the check from within the container, a la <code>docker run -it</code>. The issue with this approach is that the <code>sha</code> binary (or equivalent tool for producing a digest) might not be present (think scratch/distroless images, where you won't even have a shell). Another disadvantage is the difficulty in verifying content for architectures other than your local machine; you can pull/unpack the image for any OS/arch combo to your machine, regardless of the fact you might not be able to successfully launch a container from that image.</p>
<h2 id="whydontwejusttrusttheimagedigestasperthespec">Why don't we just trust the image digest as per the spec?</h2>
<p>Images digests serve a dual purpose; verifying that the bytes delivered over the wire have not been modified in transit, and verifying that the underlying image has not changed in the registry. Both are vital considerations in mitigating supply-channel attacks, but <strong>they don't give you any assurances that the content associated with that digest is trustworthy to begin with</strong>. If you want to be sure the binary your running is trustworthy, you have to vet it <em>as well as</em> performing your usual container security checks.</p>
<h2 id="whydontwejustbuildtheimagelocallyfromsourceourselves">Why don't we just build the image locally from source ourselves?</h2>
<p>If the project's Dockerfile includes a compilation of the binary from source, you can <code>docker build .</code> and compare the digests present between your local version and the remote via <code>docker inspect</code>. If the digests of the images match, the digests of the binaries within must also match. Not all projects have Dockerfiles that include compilation though; it is actually fairly common for docker images to pull a pre-compiled binary from some online source, or a pre-compiled version from a local directory. Remember, just because you see a Dockerfile in the root of the project, you can't always be sure that any CI pipelines associated to the project are using <em>that</em> Dockerfile ;) </p>
<p>Take the time to vet images before you run them, and when doing so, don't forget to check the binary!</p>
    </div>
    <script src="../highlight.pack.js"></script>
    <script>
    window.onload = function(){var aCodes=document.getElementsByTagName('pre');for(var i=0;i<aCodes.length;i++) {hljs.highlightBlock(aCodes[i]);}};
    </script>
  </body>
</html>